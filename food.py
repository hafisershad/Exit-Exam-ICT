# -*- coding: utf-8 -*-
"""food.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DBl5mOZARevnxbXbhSCUZysYfxXai8AL

# Importing Libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error, root_mean_squared_log_error

import warnings
warnings.filterwarnings("ignore")

"""# Reading Dataset"""

df=pd.read_csv("/content/sample_data/train.csv")

df

"""# Understanding the Dataset"""

df.shape

df.columns.tolist()

df.describe()

df.info()

df.dtypes

df.isnull().sum()

df.duplicated().sum()

df.columns.duplicated().sum()

for col in df:
    print(f"Value counts for {col}:\n{df[col].value_counts()}\n")

plot_columns = ['emailer_for_promotion','homepage_featured','center_id','meal_id']


rows = 2
cols = 2
total_plots = len(plot_columns)

fig, axes = plt.subplots(rows, cols, figsize=(18, 8))
axes = axes.flatten()

# count plot
for i, column in enumerate(plot_columns):
    sns.countplot(data=df, x=column, ax=axes[i], palette='Set2', order=df[column].value_counts().index)
    axes[i].set_title(f"Count Plot of {column}")
    axes[i].set_xlabel(column)
    axes[i].set_ylabel("Count")
    axes[i].tick_params(axis='x', rotation=85)

fig.suptitle("Univariate Analysis of train_d_set columns", fontsize=14, y=1.02)
plt.tight_layout()
plt.show()

plt.figure(figsize=(16, 6))
salary_by_gender = df.groupby('meal_id')['num_orders'].mean()
salary_by_gender.plot(kind='bar', color=['skyblue', 'orange'])
plt.title('meal_id vs num_orders')
plt.xlabel('meal_id')
plt.ylabel('num_orders')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

plt.figure(figsize=(8, 6))
salary_by_gender = df.groupby('emailer_for_promotion')['num_orders'].mean()
salary_by_gender.plot(kind='bar', color=['skyblue', 'orange'])
plt.title('emailer_for_promotion vs num_orders')
plt.xlabel('emailer_for_promotion')
plt.ylabel('num_orders')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

plt.figure(figsize=(18, 6))
salary_by_gender = df.groupby('center_id')['num_orders'].mean()
salary_by_gender.plot(kind='bar', color=['skyblue', 'orange'])
plt.title('center_id vs num_orders')
plt.xlabel('center_id')
plt.ylabel('num_orders')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

df.boxplot()
plt.xticks(rotation = 85)
plt.show()

df1=df.copy()

numerical_columns = df1.select_dtypes(include=['int64','float64'])

correlation_matrix = numerical_columns.corr()


plt.figure(figsize=(16, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

df1=df1.drop(['id'], axis=1)

# Min max scaling can be conducted to get the values in a specified range.

target_column = 'num_orders'
numerical_columns = df1.select_dtypes(include=['float64', 'int64']).columns


numerical_columns = numerical_columns[numerical_columns != target_column]

min_max = MinMaxScaler()
df1[numerical_columns] = min_max.fit_transform(df1[numerical_columns])

y=df1['num_orders']
x = df1.drop('num_orders',axis = 1)

x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=2)

ds=pd.read_csv("/content/sample_data/test_QoiMO9B.csv")

ds

ds.shape

ds.describe()

ds.info()

ds.dtypes

ds.columns.tolist()

ds.isnull().sum()

ds.duplicated().sum()

ds.boxplot()
plt.xticks(rotation = 85)
plt.show()

numerical_columns = ds.select_dtypes(include=['int64','float64'])

correlation_matrix = numerical_columns.corr()


plt.figure(figsize=(16, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

"""checkout_price and checkout_price are highly correlated.
emailer_for_promotion and homepage_featured are positively correlated.
checkout_priceand homepage_featured are negatively correlated
"""

ds=ds.drop(['id'],axis=1)

target_column = 'num_orders'


numerical_columns = ds.select_dtypes(include=['float64', 'int64']).columns


numerical_columns = numerical_columns[numerical_columns != target_column]


min_max = MinMaxScaler()
ds[numerical_columns] = min_max.fit_transform(ds[numerical_columns])

ds

"""Linear Regression"""

lin_reg = LinearRegression()
lin_reg.fit(x, y)

y_pred = lin_reg.predict(x_test)

print("evaluation metrics for linear regression:-\n")
mse = mean_squared_error(y_test, y_pred)
mae_value = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test,y_pred)

print("Mean Absolute Error:", mae_value)
print("Mean Squared Error:", mse)
print("R2 score :", r2)

"""# Decision tree"""

dec_tree= DecisionTreeRegressor()
dec_tree.fit(x,y)
y_pred = dec_tree.predict(x_test)

print("evaluation metrics for Decision Tree:-\n")
mse = mean_squared_error(y_test, y_pred)
mae_value = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test,y_pred)

print("Mean Absolute Error:", mae_value)
print("Mean Squared Error:", mse)
print("R2 score :", r2)

"""# Random Forest"""

rf_model = RandomForestRegressor()


rf_model.fit(x_train, y_train)


y_pred = rf_model.predict(x_test)


mse = mean_squared_error(y_test, y_pred)
mae_value = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test,y_pred)
RMSLE= root_mean_squared_log_error(y_test,y_pred)
print("Mean Absolute Error:", mae_value)
print("Mean Squared Error:", mse)
print("R2 score :", r2)
print("Rmsle score :", root_mean_squared_log_error)

rf_model = RandomForestRegressor()

rf_model.fit(x_train, y_train)

y_pred1 = rf_model.predict(ds)

ds1=pd.read_csv("/content/sample_data/train.csv")

# Load the test data again to retain the 'id' column for submission
ds_original = pd.read_csv("/content/sample_data/test_QoiMO9B.csv")

# Perform scaling on the ds DataFrame (where 'id' has been dropped)
target_column = 'num_orders'
numerical_columns = ds.select_dtypes(include=['float64', 'int64']).columns
numerical_columns = numerical_columns[numerical_columns != target_column]
min_max = MinMaxScaler()
ds[numerical_columns] = min_max.fit_transform(ds[numerical_columns])

# Predict using the scaled data
y_pred1 = rf_model.predict(ds)

# Create the submission DataFrame using the 'id' from the original test data
submit=pd.DataFrame({'id':ds_original['id'],
                    'num_orders': y_pred1})

#submit=pd.DataFrame({'id':ds['id'],
                    #'num_orders': y_pred1})

submit



submit.to_csv("/content/sample_data/sample_submission_hSlSoT6.csv", index=False)

